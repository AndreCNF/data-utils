{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Embedding Bag Test\n",
    "---\n",
    "\n",
    "Experimenting applying an embedding bag (embedding layer + average of all embedding vectors) on the categorical features of a time series dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# import dask.dataframe as dd                # Dask to handle big data in dataframes\n",
    "# from dask.distributed import Client        # Dask scheduler\n",
    "import pandas as pd                        # Pandas to load the data initially\n",
    "import numpy as np                         # Mathematical operations package, allowing also for missing values representation\n",
    "import torch                               # PyTorch for tensor and deep learning operations\n",
    "import data_utils as du                    # Data science and machine learning relevant methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "du.set_pandas_library('pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pixiedust                           # Debugging in Jupyter Notebook cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Initialize variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Data that we'll be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame([[103, 0, 'dog'], \n",
    "                        [103, 0, 'cat'], \n",
    "                        [103, 0, 'cat'],\n",
    "                        [103, 1, 'horse'],\n",
    "                        [103, 2, 'dog'],\n",
    "                        [104, 0, 'bunny'],\n",
    "                        [104, 1, np.nan],\n",
    "                        [104, 2, 'bunny'],\n",
    "                        [104, 3, np.nan],\n",
    "                        [105, 0, 'horse'],\n",
    "                        [105, 0, 'dog'],\n",
    "                        [105, 0, 'dog'],\n",
    "                        [105, 0, 'cat'],\n",
    "                        [105, 0, 'bunny'],\n",
    "                        [105, 0, 'horse'],\n",
    "                        [105, 1, 'horse'],\n",
    "                        [105, 1, 'bunny'],\n",
    "                        [105, 1, 'dog'],\n",
    "                        [105, 1, np.nan],\n",
    "                        [105, 1, 'horse'],\n",
    "                        [105, 1, 'horse'],\n",
    "                        [105, 1, 'horse'],\n",
    "                        [105, 1, 'horse'],\n",
    "                        [105, 1, 'horse'],\n",
    "                        [105, 1, 'horse']], columns=['id', 'ts', 'Var0'])\n",
    "# Only use the line of code bellow if you want to test on Dask\n",
    "# data_df = dd.from_pandas(data_df, npartitions=2)\n",
    "# If using Pandas, uncomment the line of code bellow and comment the next one, which uses Dask\n",
    "data_df\n",
    "# data_df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv('dummy_data/embedding_bag_data_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Embedding matrix used in the embedding layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "embed_mtx = torch.FloatTensor([[0, 0, 0],\n",
    "                               [-1, 0, 1],\n",
    "                               [0, 1, -1],\n",
    "                               [1, 1, 0],\n",
    "                               [1, -1, 1]])\n",
    "embed_mtx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Simple embedding layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "simple_embed_layer = torch.nn.Embedding.from_pretrained(embed_mtx)\n",
    "simple_embed_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Embedding layer + average operation (bagging):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "bag_embed_layer = torch.nn.EmbeddingBag.from_pretrained(embed_mtx)\n",
    "bag_embed_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## One hot encode categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data_df_ohe = du.data_processing.one_hot_encoding_dataframe(data_df, columns='Var0', join_rows=False)\n",
    "data_df_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "bool_cols = du.search_explore.list_boolean_columns(data_df_ohe)\n",
    "bool_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data_df_ohe = du.embedding.join_repeated_rows(data_df_ohe, id_columns=['id', 'ts'])\n",
    "data_df_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_ohe.to_csv('dummy_data/embedding_bag_data_df_ohe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data_df_ohe.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Enumerate categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "data_df.Var0, enum_dict = du.embedding.enum_categorical_feature(data_df, 'Var0', nan_value=0, forbidden_digit=0)\n",
    "# If using Pandas, uncomment the line of code bellow and comment the next one, which uses Dask\n",
    "data_df\n",
    "# data_df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "enum_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# If using Pandas, uncomment the line of code bellow and comment the next one, which uses Dask\n",
    "data = torch.tensor(data_df.values)\n",
    "# data = torch.tensor(data_df.compute().values)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Apply embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "simple_embed_layer(data[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "embed_data_df = pd.DataFrame(torch.cat((data[:, :2].float(), simple_embed_layer(data[:, 2])), dim=1).numpy(), columns=['id', 'ts', 'E0', 'E1', 'E2'])\n",
    "# Only use the line of code bellow if you want to test on Dask\n",
    "# embed_data_df = dd.from_pandas(embed_data_df, npartitions=2)\n",
    "# If using Pandas, uncomment the line of code bellow and comment the next one, which uses Dask\n",
    "embed_data_df\n",
    "# embed_data_df.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Apply embedding bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Var0_embed, Var0_offset = du.embedding.prepare_embed_bag(data_tnsr, features=ohe_feat)\n",
    "print(f'Var0_embed: {Var0_embed}')\n",
    "print(f'Var0_offset: {Var0_offset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "embedding_values = bag_embed_layer(Var0_embed, Var0_offset)[:-1]\n",
    "embedding_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "bag_embed_layer.embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tnsr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_values.view(data_tnsr.shape[0], data_tnsr.shape[1], bag_embed_layer.embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "embedding_values_3d = embedding_values.view(data_tnsr.shape[0], data_tnsr.shape[1], bag_embed_layer.embedding_dim)\n",
    "embedding_values_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "torch.cat((data.double(), embedding_values_3d.double()), dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Run the full embedding values calculation and tensor joining pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data_df_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data_embed = du.embedding.embedding_bag_pipeline(data_tnsr, bag_embed_layer, features=ohe_feat)\n",
    "data_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_embed = data_embed.view(-1, 5).numpy()\n",
    "data_embed = data_embed[data_embed[:, 0] != 999999]\n",
    "data_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data_df_embed = pd.DataFrame(data_embed, columns=['id', 'ts', 'E0', 'E1', 'E2'])\n",
    "data_df_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_embed.to_csv('dummy_data/embedding_bag_data_df_embed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "eICU-mortality-prediction",
   "language": "python",
   "name": "eicu-mortality-prediction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
