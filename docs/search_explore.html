<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.1" />
<title>data_utils.search_explore API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>data_utils.search_explore</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import dask.dataframe as dd                             # Dask to handle big data in dataframes
import numpy as np                                      # NumPy to handle numeric and NaN operations
import numbers                                          # numbers allows to check if data is numeric
import warnings                                         # Print warnings for bad practices
from . import utils                                     # Generic and useful methods
import data_utils as du

# Pandas to handle the data in dataframes
if du.use_modin is True:
    import modin.pandas as pd
else:
    import pandas as pd

# Ignore Dask&#39;s &#39;meta&#39; warning
warnings.filterwarnings(&#34;ignore&#34;, message=&#34;`meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.&#34;)

# Methods

def dataframe_missing_values(df, column=None):
    &#39;&#39;&#39;Returns a dataframe with the percentages of missing values of every column
    of the original dataframe.

    Parameters
    ----------
    df : pandas.DataFrame or dask.DataFrame
        Original dataframe which the user wants to analyze for missing values.
    column : string, default None
        Optional argument which, if provided, makes the function only return
        the percentage of missing values in the specified column.

    Returns
    -------
    missing_value_df : pandas.DataFrame or dask.DataFrame
        DataFrame containing the percentages of missing values for each column.
    col_percent_missing : float
        If the &#34;column&#34; argument is provided, the function only returns a float
        corresponfing to the percentage of missing values in the specified column.
    &#39;&#39;&#39;
    if column is None:
        columns = df.columns
        percent_missing = df.isnull().sum() * 100 / len(df)
        if isinstance(df, dd.DataFrame):
            # Make sure that the values are computed, in case we&#39;re using Dask
            percent_missing = percent_missing.compute()
        missing_value_df = pd.DataFrame({&#39;column_name&#39;: columns,
                                         &#39;percent_missing&#39;: percent_missing})
        missing_value_df.sort_values(&#39;percent_missing&#39;, inplace=True)
        return missing_value_df
    else:
        col_percent_missing = df[column].isnull().sum() * 100 / len(df)
        return col_percent_missing


def is_boolean_column(df, column, n_unique_values=None):
    &#39;&#39;&#39;Checks if a given column is one hot encoded.

    Parameters
    ----------
    df : pandas.DataFrame or dask.DataFrame
        Dataframe that will be used, which contains the specified column.
    column : string
        Name of the column that will be checked for boolean format.
    n_unique_values : int, default None
        Number of the column&#39;s unique values. If not specified, it will
        be automatically calculated.

    Returns
    -------
    bool
        Returns true if the column is in boolean format.
        Otherwise, returns false.
    &#39;&#39;&#39;
    if str(df[column].dtype) == &#39;boolean&#39;:
        return True
    if n_unique_values is None:
        # Calculate the number of unique values
        n_unique_values = df[column].nunique()
        if isinstance(df, dd.DataFrame):
            # Make sure that the number of unique values are computed, in case we&#39;re using Dask
            n_unique_values = n_unique_values.compute()
    # Check if it only has, at most, 2 possible values
    if n_unique_values &lt;= 2:
        unique_values = df[column].unique()
        if isinstance(df, dd.DataFrame):
            # Make sure that the unique values are computed, in case we&#39;re using Dask
            unique_values = unique_values.compute()
        # Remove NaNs from the list of unique values
        unique_values = [val for val in unique_values if not utils.is_num_nan(val)]
        # Check if the possible values are all numeric
        if (all([isinstance(x, numbers.Number) for x in unique_values])
        or all([isinstance(x, bool) or isinstance(x, np.bool_) for x in unique_values])):
            # Check if the only possible values are 0 and 1 (and ignore NaN&#39;s)
            unique_values = list(set(np.nan_to_num(unique_values)))
            unique_values.sort()
            unique_values = [val for val in unique_values if str(val).lower() != &#39;nan&#39; ]
            if ((n_unique_values == 2 and unique_values == [0, 1])
            or (n_unique_values == 1 and unique_values == [0])
            or (n_unique_values == 1 and unique_values == [1])):
                return True
    return False


def list_boolean_columns(df, search_by_dtypes=False):
    &#39;&#39;&#39;Lists the columns in a dataframe which are in a boolean format.

    Parameters
    ----------
    df : pandas.DataFrame or dask.DataFrame
        Dataframe that will be used checked for one hot encoded columns.
    search_by_dtypes : bool, default False
        If set to True, the method will only look for boolean columns based on
        their data type. This is only reliable if all the columns&#39; data types
        have been properly set.

    Returns
    -------
    list of strings
        Returns a list of the column names which correspond to one hot encoded columns.
    &#39;&#39;&#39;
    if search_by_dtypes is True:
        return [col for col in df.columns if str(df[col].dtype) == &#39;boolean&#39; or df[col].dtype == &#39;UInt8&#39;]
    else:
        # Calculate the columns&#39; number of unique values
        n_unique_values = df.nunique()
        if isinstance(df, dd.DataFrame):
            # Make sure that the number of unique values are computed, in case we&#39;re using Dask
            n_unique_values = n_unique_values.compute()
        if n_unique_values.min() &gt; 2:
            # If there are no columns with just 2 unique values, then there are no binary columns
            return []
        else:
            return [col for col in df.columns if is_boolean_column(df, col, n_unique_values[col])]


def find_col_idx(df, feature):
    &#39;&#39;&#39;Find the index that corresponds to a given feature&#39;s column number on
    a dataframe.

    Parameters
    ----------
    df : pandas.DataFrame or dask.DataFrame
        Dataframe on which to search for the feature idx
    feature : string
        Name of the feature whose index we want to find.

    Returns
    -------
    idx : int
        Index where the specified feature appears in the dataframe.&#39;&#39;&#39;
    return df.columns.get_loc(feature)


def find_val_idx(data, value, column=None):
    &#39;&#39;&#39;Find the index that corresponds to a given unique value in a data tensor.

    Parameters
    ----------
    data : torch.Tensor
        PyTorch tensor containing the data on which the desired value will
        be searched for.
    value : numeric
        Unique value whose index on the data tensor one wants to find out.
    column : int, default None
        The number of the column in the data tensor that will be searched.

    Returns
    -------
    idx : int
        Index where the specified value appears in the data tensor.&#39;&#39;&#39;
    if len(data.shape) == 1:
        val = (data == value).nonzero().squeeze()
    elif column is not None:
        if len(data.shape) == 2:
            val = (data[:, column] == value).nonzero().squeeze()
        elif len(data.shape) == 3:
            val = (data[:, :, column] == value).nonzero().squeeze()
        else:
            raise Exception(f&#39;ERROR: Currently this method only supports up to tree-dimensional data. User submitted data with {len(data.shape)} dimensions.&#39;)
    else:
        raise Exception(&#39;ERROR: If multidimensional data is being used, the column to search for must be specified in the `column` parameter.&#39;)
    if len(val.shape) &gt; 1 or len(val) &gt; 1:
        # Convert to a NumPy array
        return val.numpy()
    else:
        if val.shape[0] == 0:
            # No results found
            return None
        else:
            # Convert to a Python scalar
            return val.item()


def find_subject_idx(data, subject_id, subject_id_col=0):
    &#39;&#39;&#39;Find the index that corresponds to a given subject in a data tensor.

    Parameters
    ----------
    data : torch.Tensor
        PyTorch tensor containing the data on which the subject&#39;s index will be
        searched for.
    subject_id : int or string
        Unique identifier of the subject whose index on the data tensor one
        wants to find out.
    subject_id_col : int, default 0
        The number of the column in the data tensor that stores the subject
        identifiers.

    Returns
    -------
    idx : int
        Index where the specified subject appears in the data tensor.&#39;&#39;&#39;
    return (data[:, 0, subject_id_col] == subject_id).nonzero().item()


def find_seq_len(labels, padding_value=999999):
    &#39;&#39;&#39;Find the lengths of the sequences based on the padding values present in
    a labels tensor.

    Parameters
    ----------
    labels : torch.Tensor
        PyTorch tensor containing the data on which the subject&#39;s index will be
        searched for.
    padding_value : numeric, default 999999
        Value to use in the padding, to fill the sequences.

    Returns
    -------
    seq_lengths : torch.Tensor
        List of sequence lengths, relative to the input data.&#39;&#39;&#39;
    # Find when in each sequence the padding starts
    padding_start = ((labels == padding_value).cumsum(dim=1) == 1)
    # Detect the sequence lengths
    seq_lengths = padding_start.nonzero()[:, 1]
    if len(seq_lengths) &lt; labels.shape[0]:
        # Assign the maximum sequence length to the sequences that aren&#39;t padded
        all_zero_seq_len = (padding_start.sum(dim=1) == 0) * labels.shape[1]
        all_zero_seq_len[all_zero_seq_len == 0] = seq_lengths
        seq_lengths = all_zero_seq_len
    return seq_lengths


def find_row_contains_word(df, feature, words):
    &#39;&#39;&#39;Find if each row in a specified dataframe string feature contains some
    word from a list.

    Parameters
    ----------
    df : pandas.DataFrame or dask.DataFrame
        Dataframe containing the feature on which to run the words search.
    feature : string
        Name of the feature through which the method will search if strings
        contain any of the specified words.
    words : list of strings or string
        List of the words to search for in the feature&#39;s rows.

    Returns
    -------
    row_contains_word : pandas.Series or dask.Series
        Boolean series indicating for each row of the dataframe if its specified
        feature contains any of the words that the user is looking for.&#39;&#39;&#39;
    row_contains_word = None
    if not df[feature].dtype == &#39;object&#39;:
        raise Exception(f&#39;ERROR: The specified feature should have type &#34;object&#34;, not type {df[feature].dtype}.&#39;)
    if isinstance(words, str):
        # Make sure that the words are in a list format, even if it&#39;s just one word
        words = [words]
    if any([not isinstance(word, str) for word in words]):
        raise Exception(&#39;ERROR: All words in the specified words list should be strings.&#39;)
    if isinstance(df, dd.DataFrame):
        row_contains_word = df[feature].apply(lambda row: any([word.lower() in row.lower() for word in words]),
                                              meta=(&#39;row&#39;, bool))
    elif isinstance(df, pd.DataFrame):
        row_contains_word = df[feature].apply(lambda row: any([word.lower() in row.lower() for word in words]))
    else:
        raise Exception(f&#39;ERROR: `df` should either be a Pandas or Dask dataframe, not {type(df)}.&#39;)
    return row_contains_word


def get_element(x, n, till_the_end=False):
    &#39;&#39;&#39;Try to get an element from a list. Useful for nagging apply and map
    dataframe operations.

    Parameters
    ----------
    x : list or numpy.ndarray
        List from which to get an element.
    n : int
        Index of the element from the list that we want to retrieve.
    till_the_end : bool, default False
        If set to true, all elements from index n until the end of the list will
        be fetched. Otherwise, the method only returns the n&#39;th element.

    Returns
    -------
    y : anything
        Returns the n&#39;th element of the list or NaN if it&#39;s not found.
    &#39;&#39;&#39;
    try:
        if till_the_end is True:
            return x[n:]
        else:
            return x[n]
    except Exception:
        return np.nan


def get_element_from_split(orig_string, n, separator=&#39;|&#39;, till_the_end=False):
    &#39;&#39;&#39;Split a string by a specified separator and return the n&#39;th element of
    the obtained list of words.

    Parameters
    ----------
    orig_string : string
        Original string on which to apply the splitting and element retrieval.
    n : int
        The index of the element to return from the post-split list of words.
    separator : string, default &#39;|&#39;
        Symbol that concatenates each string&#39;s words, which will be used in the
        splitting.
    till_the_end : bool, default False
        If set to true, all elements from index n until the end of the list will
        be fetched. Otherwise, the method only returns the n&#39;th element.

    Returns
    -------
    n_element : string
        The n&#39;th element from the split string.
    &#39;&#39;&#39;
    # Split the string, by the specified separator, to get the list of all words
    split_list = orig_string.split(separator)
    # Get the n&#39;th element of the list
    n_element = get_element(split_list, n, till_the_end)
    if till_the_end is True:
        # Rejoin the elements of the list by their separator
        n_element = separator.join(n_element)
    return n_element</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="data_utils.search_explore.dataframe_missing_values"><code class="name flex">
<span>def <span class="ident">dataframe_missing_values</span></span>(<span>df, column=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a dataframe with the percentages of missing values of every column
of the original dataframe.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>df</code></strong> :&ensp;<code>pandas.DataFrame</code> or <code>dask.DataFrame</code></dt>
<dd>Original dataframe which the user wants to analyze for missing values.</dd>
<dt><strong><code>column</code></strong> :&ensp;<code>string</code>, default <code>None</code></dt>
<dd>Optional argument which, if provided, makes the function only return
the percentage of missing values in the specified column.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>missing_value_df</code></strong> :&ensp;<code>pandas.DataFrame</code> or <code>dask.DataFrame</code></dt>
<dd>DataFrame containing the percentages of missing values for each column.</dd>
<dt><strong><code>col_percent_missing</code></strong> :&ensp;<code>float</code></dt>
<dd>If the "column" argument is provided, the function only returns a float
corresponfing to the percentage of missing values in the specified column.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dataframe_missing_values(df, column=None):
    &#39;&#39;&#39;Returns a dataframe with the percentages of missing values of every column
    of the original dataframe.

    Parameters
    ----------
    df : pandas.DataFrame or dask.DataFrame
        Original dataframe which the user wants to analyze for missing values.
    column : string, default None
        Optional argument which, if provided, makes the function only return
        the percentage of missing values in the specified column.

    Returns
    -------
    missing_value_df : pandas.DataFrame or dask.DataFrame
        DataFrame containing the percentages of missing values for each column.
    col_percent_missing : float
        If the &#34;column&#34; argument is provided, the function only returns a float
        corresponfing to the percentage of missing values in the specified column.
    &#39;&#39;&#39;
    if column is None:
        columns = df.columns
        percent_missing = df.isnull().sum() * 100 / len(df)
        if isinstance(df, dd.DataFrame):
            # Make sure that the values are computed, in case we&#39;re using Dask
            percent_missing = percent_missing.compute()
        missing_value_df = pd.DataFrame({&#39;column_name&#39;: columns,
                                         &#39;percent_missing&#39;: percent_missing})
        missing_value_df.sort_values(&#39;percent_missing&#39;, inplace=True)
        return missing_value_df
    else:
        col_percent_missing = df[column].isnull().sum() * 100 / len(df)
        return col_percent_missing</code></pre>
</details>
</dd>
<dt id="data_utils.search_explore.find_col_idx"><code class="name flex">
<span>def <span class="ident">find_col_idx</span></span>(<span>df, feature)</span>
</code></dt>
<dd>
<div class="desc"><p>Find the index that corresponds to a given feature's column number on
a dataframe.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>df</code></strong> :&ensp;<code>pandas.DataFrame</code> or <code>dask.DataFrame</code></dt>
<dd>Dataframe on which to search for the feature idx</dd>
<dt><strong><code>feature</code></strong> :&ensp;<code>string</code></dt>
<dd>Name of the feature whose index we want to find.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>idx</code></strong> :&ensp;<code>int</code></dt>
<dd>Index where the specified feature appears in the dataframe.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_col_idx(df, feature):
    &#39;&#39;&#39;Find the index that corresponds to a given feature&#39;s column number on
    a dataframe.

    Parameters
    ----------
    df : pandas.DataFrame or dask.DataFrame
        Dataframe on which to search for the feature idx
    feature : string
        Name of the feature whose index we want to find.

    Returns
    -------
    idx : int
        Index where the specified feature appears in the dataframe.&#39;&#39;&#39;
    return df.columns.get_loc(feature)</code></pre>
</details>
</dd>
<dt id="data_utils.search_explore.find_row_contains_word"><code class="name flex">
<span>def <span class="ident">find_row_contains_word</span></span>(<span>df, feature, words)</span>
</code></dt>
<dd>
<div class="desc"><p>Find if each row in a specified dataframe string feature contains some
word from a list.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>df</code></strong> :&ensp;<code>pandas.DataFrame</code> or <code>dask.DataFrame</code></dt>
<dd>Dataframe containing the feature on which to run the words search.</dd>
<dt><strong><code>feature</code></strong> :&ensp;<code>string</code></dt>
<dd>Name of the feature through which the method will search if strings
contain any of the specified words.</dd>
<dt><strong><code>words</code></strong> :&ensp;<code>list</code> of <code>strings</code> or <code>string</code></dt>
<dd>List of the words to search for in the feature's rows.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>row_contains_word</code></strong> :&ensp;<code>pandas.Series</code> or <code>dask.Series</code></dt>
<dd>Boolean series indicating for each row of the dataframe if its specified
feature contains any of the words that the user is looking for.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_row_contains_word(df, feature, words):
    &#39;&#39;&#39;Find if each row in a specified dataframe string feature contains some
    word from a list.

    Parameters
    ----------
    df : pandas.DataFrame or dask.DataFrame
        Dataframe containing the feature on which to run the words search.
    feature : string
        Name of the feature through which the method will search if strings
        contain any of the specified words.
    words : list of strings or string
        List of the words to search for in the feature&#39;s rows.

    Returns
    -------
    row_contains_word : pandas.Series or dask.Series
        Boolean series indicating for each row of the dataframe if its specified
        feature contains any of the words that the user is looking for.&#39;&#39;&#39;
    row_contains_word = None
    if not df[feature].dtype == &#39;object&#39;:
        raise Exception(f&#39;ERROR: The specified feature should have type &#34;object&#34;, not type {df[feature].dtype}.&#39;)
    if isinstance(words, str):
        # Make sure that the words are in a list format, even if it&#39;s just one word
        words = [words]
    if any([not isinstance(word, str) for word in words]):
        raise Exception(&#39;ERROR: All words in the specified words list should be strings.&#39;)
    if isinstance(df, dd.DataFrame):
        row_contains_word = df[feature].apply(lambda row: any([word.lower() in row.lower() for word in words]),
                                              meta=(&#39;row&#39;, bool))
    elif isinstance(df, pd.DataFrame):
        row_contains_word = df[feature].apply(lambda row: any([word.lower() in row.lower() for word in words]))
    else:
        raise Exception(f&#39;ERROR: `df` should either be a Pandas or Dask dataframe, not {type(df)}.&#39;)
    return row_contains_word</code></pre>
</details>
</dd>
<dt id="data_utils.search_explore.find_seq_len"><code class="name flex">
<span>def <span class="ident">find_seq_len</span></span>(<span>labels, padding_value=999999)</span>
</code></dt>
<dd>
<div class="desc"><p>Find the lengths of the sequences based on the padding values present in
a labels tensor.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>labels</code></strong> :&ensp;<code>torch.Tensor</code></dt>
<dd>PyTorch tensor containing the data on which the subject's index will be
searched for.</dd>
<dt><strong><code>padding_value</code></strong> :&ensp;<code>numeric</code>, default <code>999999</code></dt>
<dd>Value to use in the padding, to fill the sequences.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>seq_lengths</code></strong> :&ensp;<code>torch.Tensor</code></dt>
<dd>List of sequence lengths, relative to the input data.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_seq_len(labels, padding_value=999999):
    &#39;&#39;&#39;Find the lengths of the sequences based on the padding values present in
    a labels tensor.

    Parameters
    ----------
    labels : torch.Tensor
        PyTorch tensor containing the data on which the subject&#39;s index will be
        searched for.
    padding_value : numeric, default 999999
        Value to use in the padding, to fill the sequences.

    Returns
    -------
    seq_lengths : torch.Tensor
        List of sequence lengths, relative to the input data.&#39;&#39;&#39;
    # Find when in each sequence the padding starts
    padding_start = ((labels == padding_value).cumsum(dim=1) == 1)
    # Detect the sequence lengths
    seq_lengths = padding_start.nonzero()[:, 1]
    if len(seq_lengths) &lt; labels.shape[0]:
        # Assign the maximum sequence length to the sequences that aren&#39;t padded
        all_zero_seq_len = (padding_start.sum(dim=1) == 0) * labels.shape[1]
        all_zero_seq_len[all_zero_seq_len == 0] = seq_lengths
        seq_lengths = all_zero_seq_len
    return seq_lengths</code></pre>
</details>
</dd>
<dt id="data_utils.search_explore.find_subject_idx"><code class="name flex">
<span>def <span class="ident">find_subject_idx</span></span>(<span>data, subject_id, subject_id_col=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Find the index that corresponds to a given subject in a data tensor.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>torch.Tensor</code></dt>
<dd>PyTorch tensor containing the data on which the subject's index will be
searched for.</dd>
<dt><strong><code>subject_id</code></strong> :&ensp;<code>int</code> or <code>string</code></dt>
<dd>Unique identifier of the subject whose index on the data tensor one
wants to find out.</dd>
<dt><strong><code>subject_id_col</code></strong> :&ensp;<code>int</code>, default <code>0</code></dt>
<dd>The number of the column in the data tensor that stores the subject
identifiers.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>idx</code></strong> :&ensp;<code>int</code></dt>
<dd>Index where the specified subject appears in the data tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_subject_idx(data, subject_id, subject_id_col=0):
    &#39;&#39;&#39;Find the index that corresponds to a given subject in a data tensor.

    Parameters
    ----------
    data : torch.Tensor
        PyTorch tensor containing the data on which the subject&#39;s index will be
        searched for.
    subject_id : int or string
        Unique identifier of the subject whose index on the data tensor one
        wants to find out.
    subject_id_col : int, default 0
        The number of the column in the data tensor that stores the subject
        identifiers.

    Returns
    -------
    idx : int
        Index where the specified subject appears in the data tensor.&#39;&#39;&#39;
    return (data[:, 0, subject_id_col] == subject_id).nonzero().item()</code></pre>
</details>
</dd>
<dt id="data_utils.search_explore.find_val_idx"><code class="name flex">
<span>def <span class="ident">find_val_idx</span></span>(<span>data, value, column=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Find the index that corresponds to a given unique value in a data tensor.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>torch.Tensor</code></dt>
<dd>PyTorch tensor containing the data on which the desired value will
be searched for.</dd>
<dt><strong><code>value</code></strong> :&ensp;<code>numeric</code></dt>
<dd>Unique value whose index on the data tensor one wants to find out.</dd>
<dt><strong><code>column</code></strong> :&ensp;<code>int</code>, default <code>None</code></dt>
<dd>The number of the column in the data tensor that will be searched.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>idx</code></strong> :&ensp;<code>int</code></dt>
<dd>Index where the specified value appears in the data tensor.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_val_idx(data, value, column=None):
    &#39;&#39;&#39;Find the index that corresponds to a given unique value in a data tensor.

    Parameters
    ----------
    data : torch.Tensor
        PyTorch tensor containing the data on which the desired value will
        be searched for.
    value : numeric
        Unique value whose index on the data tensor one wants to find out.
    column : int, default None
        The number of the column in the data tensor that will be searched.

    Returns
    -------
    idx : int
        Index where the specified value appears in the data tensor.&#39;&#39;&#39;
    if len(data.shape) == 1:
        val = (data == value).nonzero().squeeze()
    elif column is not None:
        if len(data.shape) == 2:
            val = (data[:, column] == value).nonzero().squeeze()
        elif len(data.shape) == 3:
            val = (data[:, :, column] == value).nonzero().squeeze()
        else:
            raise Exception(f&#39;ERROR: Currently this method only supports up to tree-dimensional data. User submitted data with {len(data.shape)} dimensions.&#39;)
    else:
        raise Exception(&#39;ERROR: If multidimensional data is being used, the column to search for must be specified in the `column` parameter.&#39;)
    if len(val.shape) &gt; 1 or len(val) &gt; 1:
        # Convert to a NumPy array
        return val.numpy()
    else:
        if val.shape[0] == 0:
            # No results found
            return None
        else:
            # Convert to a Python scalar
            return val.item()</code></pre>
</details>
</dd>
<dt id="data_utils.search_explore.get_element"><code class="name flex">
<span>def <span class="ident">get_element</span></span>(<span>x, n, till_the_end=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Try to get an element from a list. Useful for nagging apply and map
dataframe operations.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>list</code> or <code>numpy.ndarray</code></dt>
<dd>List from which to get an element.</dd>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>Index of the element from the list that we want to retrieve.</dd>
<dt><strong><code>till_the_end</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>If set to true, all elements from index n until the end of the list will
be fetched. Otherwise, the method only returns the n'th element.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>y</code></strong> :&ensp;<code>anything</code></dt>
<dd>Returns the n'th element of the list or NaN if it's not found.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_element(x, n, till_the_end=False):
    &#39;&#39;&#39;Try to get an element from a list. Useful for nagging apply and map
    dataframe operations.

    Parameters
    ----------
    x : list or numpy.ndarray
        List from which to get an element.
    n : int
        Index of the element from the list that we want to retrieve.
    till_the_end : bool, default False
        If set to true, all elements from index n until the end of the list will
        be fetched. Otherwise, the method only returns the n&#39;th element.

    Returns
    -------
    y : anything
        Returns the n&#39;th element of the list or NaN if it&#39;s not found.
    &#39;&#39;&#39;
    try:
        if till_the_end is True:
            return x[n:]
        else:
            return x[n]
    except Exception:
        return np.nan</code></pre>
</details>
</dd>
<dt id="data_utils.search_explore.get_element_from_split"><code class="name flex">
<span>def <span class="ident">get_element_from_split</span></span>(<span>orig_string, n, separator='|', till_the_end=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Split a string by a specified separator and return the n'th element of
the obtained list of words.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>orig_string</code></strong> :&ensp;<code>string</code></dt>
<dd>Original string on which to apply the splitting and element retrieval.</dd>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>The index of the element to return from the post-split list of words.</dd>
<dt><strong><code>separator</code></strong> :&ensp;<code>string</code>, default <code>'|'</code></dt>
<dd>Symbol that concatenates each string's words, which will be used in the
splitting.</dd>
<dt><strong><code>till_the_end</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>If set to true, all elements from index n until the end of the list will
be fetched. Otherwise, the method only returns the n'th element.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>n_element</code></strong> :&ensp;<code>string</code></dt>
<dd>The n'th element from the split string.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_element_from_split(orig_string, n, separator=&#39;|&#39;, till_the_end=False):
    &#39;&#39;&#39;Split a string by a specified separator and return the n&#39;th element of
    the obtained list of words.

    Parameters
    ----------
    orig_string : string
        Original string on which to apply the splitting and element retrieval.
    n : int
        The index of the element to return from the post-split list of words.
    separator : string, default &#39;|&#39;
        Symbol that concatenates each string&#39;s words, which will be used in the
        splitting.
    till_the_end : bool, default False
        If set to true, all elements from index n until the end of the list will
        be fetched. Otherwise, the method only returns the n&#39;th element.

    Returns
    -------
    n_element : string
        The n&#39;th element from the split string.
    &#39;&#39;&#39;
    # Split the string, by the specified separator, to get the list of all words
    split_list = orig_string.split(separator)
    # Get the n&#39;th element of the list
    n_element = get_element(split_list, n, till_the_end)
    if till_the_end is True:
        # Rejoin the elements of the list by their separator
        n_element = separator.join(n_element)
    return n_element</code></pre>
</details>
</dd>
<dt id="data_utils.search_explore.is_boolean_column"><code class="name flex">
<span>def <span class="ident">is_boolean_column</span></span>(<span>df, column, n_unique_values=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Checks if a given column is one hot encoded.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>df</code></strong> :&ensp;<code>pandas.DataFrame</code> or <code>dask.DataFrame</code></dt>
<dd>Dataframe that will be used, which contains the specified column.</dd>
<dt><strong><code>column</code></strong> :&ensp;<code>string</code></dt>
<dd>Name of the column that will be checked for boolean format.</dd>
<dt><strong><code>n_unique_values</code></strong> :&ensp;<code>int</code>, default <code>None</code></dt>
<dd>Number of the column's unique values. If not specified, it will
be automatically calculated.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>Returns true if the column is in boolean format.
Otherwise, returns false.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_boolean_column(df, column, n_unique_values=None):
    &#39;&#39;&#39;Checks if a given column is one hot encoded.

    Parameters
    ----------
    df : pandas.DataFrame or dask.DataFrame
        Dataframe that will be used, which contains the specified column.
    column : string
        Name of the column that will be checked for boolean format.
    n_unique_values : int, default None
        Number of the column&#39;s unique values. If not specified, it will
        be automatically calculated.

    Returns
    -------
    bool
        Returns true if the column is in boolean format.
        Otherwise, returns false.
    &#39;&#39;&#39;
    if str(df[column].dtype) == &#39;boolean&#39;:
        return True
    if n_unique_values is None:
        # Calculate the number of unique values
        n_unique_values = df[column].nunique()
        if isinstance(df, dd.DataFrame):
            # Make sure that the number of unique values are computed, in case we&#39;re using Dask
            n_unique_values = n_unique_values.compute()
    # Check if it only has, at most, 2 possible values
    if n_unique_values &lt;= 2:
        unique_values = df[column].unique()
        if isinstance(df, dd.DataFrame):
            # Make sure that the unique values are computed, in case we&#39;re using Dask
            unique_values = unique_values.compute()
        # Remove NaNs from the list of unique values
        unique_values = [val for val in unique_values if not utils.is_num_nan(val)]
        # Check if the possible values are all numeric
        if (all([isinstance(x, numbers.Number) for x in unique_values])
        or all([isinstance(x, bool) or isinstance(x, np.bool_) for x in unique_values])):
            # Check if the only possible values are 0 and 1 (and ignore NaN&#39;s)
            unique_values = list(set(np.nan_to_num(unique_values)))
            unique_values.sort()
            unique_values = [val for val in unique_values if str(val).lower() != &#39;nan&#39; ]
            if ((n_unique_values == 2 and unique_values == [0, 1])
            or (n_unique_values == 1 and unique_values == [0])
            or (n_unique_values == 1 and unique_values == [1])):
                return True
    return False</code></pre>
</details>
</dd>
<dt id="data_utils.search_explore.list_boolean_columns"><code class="name flex">
<span>def <span class="ident">list_boolean_columns</span></span>(<span>df, search_by_dtypes=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Lists the columns in a dataframe which are in a boolean format.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>df</code></strong> :&ensp;<code>pandas.DataFrame</code> or <code>dask.DataFrame</code></dt>
<dd>Dataframe that will be used checked for one hot encoded columns.</dd>
<dt><strong><code>search_by_dtypes</code></strong> :&ensp;<code>bool</code>, default <code>False</code></dt>
<dd>If set to True, the method will only look for boolean columns based on
their data type. This is only reliable if all the columns' data types
have been properly set.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code> of <code>strings</code></dt>
<dd>Returns a list of the column names which correspond to one hot encoded columns.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def list_boolean_columns(df, search_by_dtypes=False):
    &#39;&#39;&#39;Lists the columns in a dataframe which are in a boolean format.

    Parameters
    ----------
    df : pandas.DataFrame or dask.DataFrame
        Dataframe that will be used checked for one hot encoded columns.
    search_by_dtypes : bool, default False
        If set to True, the method will only look for boolean columns based on
        their data type. This is only reliable if all the columns&#39; data types
        have been properly set.

    Returns
    -------
    list of strings
        Returns a list of the column names which correspond to one hot encoded columns.
    &#39;&#39;&#39;
    if search_by_dtypes is True:
        return [col for col in df.columns if str(df[col].dtype) == &#39;boolean&#39; or df[col].dtype == &#39;UInt8&#39;]
    else:
        # Calculate the columns&#39; number of unique values
        n_unique_values = df.nunique()
        if isinstance(df, dd.DataFrame):
            # Make sure that the number of unique values are computed, in case we&#39;re using Dask
            n_unique_values = n_unique_values.compute()
        if n_unique_values.min() &gt; 2:
            # If there are no columns with just 2 unique values, then there are no binary columns
            return []
        else:
            return [col for col in df.columns if is_boolean_column(df, col, n_unique_values[col])]</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="data_utils" href="index.html">data_utils</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="data_utils.search_explore.dataframe_missing_values" href="#data_utils.search_explore.dataframe_missing_values">dataframe_missing_values</a></code></li>
<li><code><a title="data_utils.search_explore.find_col_idx" href="#data_utils.search_explore.find_col_idx">find_col_idx</a></code></li>
<li><code><a title="data_utils.search_explore.find_row_contains_word" href="#data_utils.search_explore.find_row_contains_word">find_row_contains_word</a></code></li>
<li><code><a title="data_utils.search_explore.find_seq_len" href="#data_utils.search_explore.find_seq_len">find_seq_len</a></code></li>
<li><code><a title="data_utils.search_explore.find_subject_idx" href="#data_utils.search_explore.find_subject_idx">find_subject_idx</a></code></li>
<li><code><a title="data_utils.search_explore.find_val_idx" href="#data_utils.search_explore.find_val_idx">find_val_idx</a></code></li>
<li><code><a title="data_utils.search_explore.get_element" href="#data_utils.search_explore.get_element">get_element</a></code></li>
<li><code><a title="data_utils.search_explore.get_element_from_split" href="#data_utils.search_explore.get_element_from_split">get_element_from_split</a></code></li>
<li><code><a title="data_utils.search_explore.is_boolean_column" href="#data_utils.search_explore.is_boolean_column">is_boolean_column</a></code></li>
<li><code><a title="data_utils.search_explore.list_boolean_columns" href="#data_utils.search_explore.list_boolean_columns">list_boolean_columns</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.1</a>.</p>
</footer>
</body>
</html>